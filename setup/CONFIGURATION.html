
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Configuration Â· GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-prism/prism.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="../COMMAND.html" />
    
    
    <link rel="prev" href="QUICKSTART.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    hls4ml
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../RELEASENOTES.html">
            
                <a href="../RELEASENOTES.html">
            
                    
                    Release Notes
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="../STATUS.html">
            
                <a href="../STATUS.html">
            
                    
                    Status and Features
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="../SETUP.html">
            
                <a href="../SETUP.html">
            
                    
                    Setup
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.1" data-path="DEPENDENCIES.html">
            
                <a href="DEPENDENCIES.html">
            
                    
                    Dependencies
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.2" data-path="QUICKSTART.html">
            
                <a href="QUICKSTART.html">
            
                    
                    Quick Start
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.4.3" data-path="CONFIGURATION.html">
            
                <a href="CONFIGURATION.html">
            
                    
                    Configuration
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="../COMMAND.html">
            
                <a href="../COMMAND.html">
            
                    
                    Command help
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="../PROFILING.html">
            
                <a href="../PROFILING.html">
            
                    
                    Profiling
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="../CONCEPTS.html">
            
                <a href="../CONCEPTS.html">
            
                    
                    Concepts
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8" data-path="../REFERENCE.html">
            
                <a href="../REFERENCE.html">
            
                    
                    Reference and Contributors
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9" >
            
                <a target="_blank" href="https://github.com/hls-fpga-machine-learning/HLS4ML">
            
                    
                    Code Repository
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >Configuration</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="configuration">Configuration</h1>
<hr>
<p>Now that you have a run a quick example workflow of hls4ml, let&apos;s go through the various configuration options that you have for the translation of your machine learning algorithm.  </p>
<p>One important part of hls4ml to remember is that the user is responsible for the format of the inputs.  There is no automatic formatting or normalization so this must be done in the training. </p>
<hr>
<h2 id="keras-translation">Keras translation</h2>
<h3 id="top-level-configuration">Top level configuration</h3>
<p>Configuration files are YAML files in hls4ml (<code>*.yml</code>). An example configuration file is <a href="https://github.com/hls-fpga-machine-learning/hls4ml/blob/master/example-models/keras-config.yml" target="_blank">here</a>.</p>
<p>It looks like this:</p>
<pre class="language-"><code class="lang-yaml"><span class="token key atrule">KerasJson</span><span class="token punctuation">:</span> keras/KERAS_3layer.json
<span class="token key atrule">KerasH5</span><span class="token punctuation">:</span>   keras/KERAS_3layer_weights.h5 <span class="token comment">#You can also use h5 file from Keras&apos;s model.save() without supplying json file.</span>
<span class="token key atrule">InputData</span><span class="token punctuation">:</span> keras/KERAS_3layer_input_features.dat
<span class="token key atrule">OutputPredictions</span><span class="token punctuation">:</span> keras/KERAS_3layer_predictions.dat
<span class="token key atrule">OutputDir</span><span class="token punctuation">:</span> my<span class="token punctuation">-</span>hls<span class="token punctuation">-</span>test
<span class="token key atrule">ProjectName</span><span class="token punctuation">:</span> myproject
<span class="token key atrule">XilinxPart</span><span class="token punctuation">:</span> xcku115<span class="token punctuation">-</span>flvb2104<span class="token punctuation">-</span>2<span class="token punctuation">-</span>i
<span class="token key atrule">ClockPeriod</span><span class="token punctuation">:</span> <span class="token number">5</span>

<span class="token key atrule">IOType</span><span class="token punctuation">:</span> io_parallel <span class="token comment"># options: io_serial/io_parallel</span>
<span class="token key atrule">HLSConfig</span><span class="token punctuation">:</span>
  <span class="token key atrule">Model</span><span class="token punctuation">:</span>
    <span class="token key atrule">Precision</span><span class="token punctuation">:</span> ap_fixed&lt;16<span class="token punctuation">,</span>6<span class="token punctuation">&gt;</span>
    <span class="token key atrule">ReuseFactor</span><span class="token punctuation">:</span> <span class="token number">1</span>
    <span class="token key atrule">Strategy</span><span class="token punctuation">:</span> Latency 
  <span class="token key atrule">LayerType</span><span class="token punctuation">:</span>
    <span class="token key atrule">Dense</span><span class="token punctuation">:</span>
      <span class="token key atrule">ReuseFactor</span><span class="token punctuation">:</span> <span class="token number">2</span>
      <span class="token key atrule">Strategy</span><span class="token punctuation">:</span> Resource
      <span class="token key atrule">Compression</span><span class="token punctuation">:</span> <span class="token boolean important">True</span>
</code></pre>
<p>There are a number of configuration options that you have.  Let&apos;s go through them.  You have basic setup parameters: </p>
<ul>
<li><strong>KerasJson/KerasH5</strong>: for Keras, the model architecture and weights are stored in a <code>json</code> and <code>h5</code> file.  The path to those files are required here. 
We also support keras model&apos;s file obtained just from <code>model.save()</code>. In this case you can just supply the <code>h5</code> file in <code>KerasH5:</code> field.</li>
<li><strong>InputData/OutputPredictions</strong>: path to your input/predictions of the model. If none is supplied, then hls4ml will create aritificial data for simulation. The data used above in the example can be found <a href="https://cernbox.cern.ch/index.php/s/2LTJVVwCYFfkg59" target="_blank">here</a>. We also support <code>npy</code> data files. We welcome suggestions on more input data types to support. </li>
<li><strong>OutputDir</strong>: the output directory where you want your HLS project to appear</li>
<li><strong>ProjectName</strong>: the name of the HLS project IP that is produced</li>
<li><strong>XilinxPart</strong>: the particular FPGA part number that you are considering, here it&apos;s a Xilinx Virtex-7 FPGA</li>
<li><strong>ClockPeriod</strong>: the clock period, in ns, at which your algorithm runs
Then you have some optimization parameters for how your algorithm runs:</li>
<li><strong>IOType</strong>: your options are <code>io_parallel</code> or <code>io_serial</code> where this really defines if you are pipelining your algorithm or not</li>
<li><strong>ReuseFactor</strong>: in the case that you are pipelining, this defines the pipeline interval or initiation interval</li>
<li><strong>Strategy</strong>: Optimization strategy on FPGA, either &quot;Latency&quot; or &quot;Resource&quot;. If none is supplied then hl4ml uses &quot;Latency&quot; as default. Note that a reuse factor larger than 1 should be specified when using &quot;resource&quot; strategy. An example of using larger reuse factor can be found <a href="https://github.com/hls-fpga-machine-learning/models/tree/master/keras/KERAS_dense" target="_blank">here.</a></li>
<li><strong>Precision</strong>: this defines the precsion of your inputs, outputs, weights and biases. It is denoted by <code>ap_fixed<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>X,Y</span><span class="token punctuation">&gt;</span></span></code>, where <code>Y</code> is the number of bits representing the signed number above the binary point (i.e. the integer part), and <code>X</code> is the total number of bits.
Additionally, integers in fixed precision data type (<code>ap_int<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>N</span><span class="token punctuation">&gt;</span></span></code>, where <code>N</code> is a bit-size from 1 to 1024) can also be used. You have a chance to further configure this more finely with per-layer configuration described below.</li>
</ul>
<p><strong>Per-layer configuration:</strong>
In the hls4ml configuration file, it is possible to specify the model <em>Precision</em> and <em>ReuseFactor</em> with finer granularity.</p>
<p>Under the <code>HLSConfig</code> heading, these can be set for the <code>Model</code>, per <code>LayerType</code>, per <code>LayerName</code>, and for named variables within the layer (for precision only). The most basic configuration may look like this:</p>
<pre class="language-"><code class="lang-yaml"><span class="token key atrule">HLSConfig</span><span class="token punctuation">:</span>
  <span class="token key atrule">Model</span><span class="token punctuation">:</span>
    <span class="token key atrule">Precision</span><span class="token punctuation">:</span> ap_fixed&lt;16<span class="token punctuation">,</span>6<span class="token punctuation">&gt;</span>
    <span class="token key atrule">ReuseFactor</span><span class="token punctuation">:</span> <span class="token number">1</span>
</code></pre>
<p>This configuration use <code>ap_fixed&lt;16,6&gt;</code> for every variable and a ReuseFactor of 1 throughout.</p>
<p>Specify all <code>Dense</code> layers to use a different precision like this:</p>
<pre class="language-"><code class="lang-yaml"><span class="token key atrule">HLSConfig</span><span class="token punctuation">:</span>
  <span class="token key atrule">Model</span><span class="token punctuation">:</span>
    <span class="token key atrule">Precision</span><span class="token punctuation">:</span> ap_fixed&lt;16<span class="token punctuation">,</span>6<span class="token punctuation">&gt;</span>
    <span class="token key atrule">ReuseFactor</span><span class="token punctuation">:</span> <span class="token number">1</span>
  <span class="token key atrule">LayerType</span><span class="token punctuation">:</span>
    <span class="token key atrule">Dense</span><span class="token punctuation">:</span>
      <span class="token key atrule">Precision</span><span class="token punctuation">:</span> ap_fixed&lt;14<span class="token punctuation">,</span>5<span class="token punctuation">&gt;</span>
</code></pre>
<p>In this case, all variables in any <code>Dense</code> layers will be represented with <code>ap_fixed&lt;14,5&gt;</code> while any other layer types will use <code>ap_fixed&lt;16,6&gt;</code>.</p>
<p>A specific layer can be targeted like this:</p>
<pre class="language-"><code class="lang-yaml"> <span class="token key atrule">HLSConfig</span><span class="token punctuation">:</span>
    <span class="token key atrule">Model</span><span class="token punctuation">:</span>
      <span class="token key atrule">Precision</span><span class="token punctuation">:</span> ap_fixed&lt;16<span class="token punctuation">,</span>6<span class="token punctuation">&gt;</span>
      <span class="token key atrule">ReuseFactor</span><span class="token punctuation">:</span> <span class="token number">16</span>
    <span class="token key atrule">LayerName</span><span class="token punctuation">:</span>
      <span class="token key atrule">dense1</span><span class="token punctuation">:</span>
        <span class="token key atrule">Precision</span><span class="token punctuation">:</span> 
          <span class="token key atrule">weight</span><span class="token punctuation">:</span> ap_fixed&lt;14<span class="token punctuation">,</span>2<span class="token punctuation">&gt;</span>
          <span class="token key atrule">bias</span><span class="token punctuation">:</span> ap_fixed&lt;14<span class="token punctuation">,</span>4<span class="token punctuation">&gt;</span>
          <span class="token key atrule">result</span><span class="token punctuation">:</span> ap_fixed&lt;16<span class="token punctuation">,</span>6<span class="token punctuation">&gt;</span>
        <span class="token key atrule">ReuseFactor</span><span class="token punctuation">:</span> <span class="token number">12</span>
        <span class="token key atrule">Strategy</span><span class="token punctuation">:</span> Resource
</code></pre>
<p>In this case, the default model configuration will use <code>ap_fixed&lt;16,6&gt;</code> and a <code>ReuseFactor</code> of 16. The layer named <code>dense1</code> (defined in the user provided model architecture file) will instead use different precision for the <code>weight</code>, <code>bias</code>, and <code>result</code> (output) variables, a <code>ReuseFactor</code> of 12, and the <code>Resource</code> strategy (while the model default is <code>Latency</code> strategy.</p>
<p>More than one layer can have a configuration specified, e.g.:</p>
<pre class="language-"><code class="lang-yaml"><span class="token key atrule">HLSConfig</span><span class="token punctuation">:</span>
  <span class="token key atrule">Model</span><span class="token punctuation">:</span>
   <span class="token punctuation">...</span>
  <span class="token key atrule">LayerName</span><span class="token punctuation">:</span>
    <span class="token key atrule">dense1</span><span class="token punctuation">:</span>
       <span class="token punctuation">...</span>
    <span class="token key atrule">batchnormalization1</span><span class="token punctuation">:</span>
       <span class="token punctuation">...</span>
    <span class="token key atrule">dense2</span><span class="token punctuation">:</span>
       <span class="token punctuation">...</span>
</code></pre>
<p>For more information on the optimization parameters and what they mean, you can visit the <a href="../CONCEPTS.html">Concepts</a> chapter.</p>
<hr>
<h3 id="detailed-configuration-in-converted-hls-codes">Detailed configuration in converted hls codes</h3>
<p><strong>NOTE</strong>: this section is developer-oriented.</p>
<p>After you create your project, you have the opportunity to do more configuration if you so choose.<br>In your project, the file <code><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>OutputDir</span><span class="token punctuation">&gt;</span></span>/firmware/<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>ProjectName</span><span class="token punctuation">&gt;</span></span>.cpp</code> is your top level file.  It has the network architecture constructed for you.  An example is <a href="https://github.com/hls-fpga-machine-learning/models/blob/master/HLS_projects/KERAS-1layer-hls/firmware/myproject.cpp" target="_blank">here</a> and the important snippet is:</p>
<pre class="language-"><code class="lang-cpp">layer2_t layer2_out<span class="token punctuation">[</span>N_LAYER_2<span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token macro property">#<span class="token directive keyword">pragma</span> HLS ARRAY_PARTITION variable=layer2_out complete dim=0</span>
nnet<span class="token operator">::</span>dense_latency<span class="token operator">&lt;</span>input_t<span class="token punctuation">,</span> layer2_t<span class="token punctuation">,</span> config2<span class="token operator">&gt;</span><span class="token punctuation">(</span>input_1<span class="token punctuation">,</span> layer2_out<span class="token punctuation">,</span> w2<span class="token punctuation">,</span> b2<span class="token punctuation">)</span><span class="token punctuation">;</span>

layer3_t layer3_out<span class="token punctuation">[</span>N_LAYER_2<span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token macro property">#<span class="token directive keyword">pragma</span> HLS ARRAY_PARTITION variable=layer3_out complete dim=0</span>
nnet<span class="token operator">::</span>relu<span class="token operator">&lt;</span>layer2_t<span class="token punctuation">,</span> layer3_t<span class="token punctuation">,</span> relu_config3<span class="token operator">&gt;</span><span class="token punctuation">(</span>layer2_out<span class="token punctuation">,</span> layer3_out<span class="token punctuation">)</span><span class="token punctuation">;</span>

layer4_t layer4_out<span class="token punctuation">[</span>N_LAYER_4<span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token macro property">#<span class="token directive keyword">pragma</span> HLS ARRAY_PARTITION variable=layer4_out complete dim=0</span>
nnet<span class="token operator">::</span>dense_latency<span class="token operator">&lt;</span>layer3_t<span class="token punctuation">,</span> layer4_t<span class="token punctuation">,</span> config4<span class="token operator">&gt;</span><span class="token punctuation">(</span>layer3_out<span class="token punctuation">,</span> layer4_out<span class="token punctuation">,</span> w4<span class="token punctuation">,</span> b4<span class="token punctuation">)</span><span class="token punctuation">;</span>

nnet<span class="token operator">::</span>sigmoid<span class="token operator">&lt;</span>layer4_t<span class="token punctuation">,</span> result_t<span class="token punctuation">,</span> sigmoid_config5<span class="token operator">&gt;</span><span class="token punctuation">(</span>layer4_out<span class="token punctuation">,</span> layer5_out<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>You can see, for the simple 1-layer DNN, the computation (<code>nnet::dense_latency</code>) and activation (<code>nnet::relu</code>/<code>nnet::sigmoid</code>) caluclation for each layer.  For each layer, it has its own additional configuration parameters, e.g. <code>config2</code>.</p>
<p>In your project, the file <code><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>OutputDir</span><span class="token punctuation">&gt;</span></span>/firmware/parameters.h</code> stores all the configuration options for each neural network library.
An example is <a href="https://github.com/hls-fpga-machine-learning/models/blob/master/HLS_projects/KERAS-1layer-hls/firmware/parameters.h" target="_blank">here</a>. So for example, the detailed configuration options for an example DNN layer is:</p>
<pre class="language-"><code class="lang-cpp"><span class="token comment">//hls-fpga-machine-learning insert layer-config</span>
<span class="token keyword">struct</span> <span class="token class-name">config2</span> <span class="token operator">:</span> nnet<span class="token operator">::</span>dense_config <span class="token punctuation">{</span>
    <span class="token keyword">static</span> <span class="token keyword">const</span> <span class="token keyword">unsigned</span> n_in <span class="token operator">=</span> N_INPUT_1_1<span class="token punctuation">;</span>
    <span class="token keyword">static</span> <span class="token keyword">const</span> <span class="token keyword">unsigned</span> n_out <span class="token operator">=</span> N_LAYER_2<span class="token punctuation">;</span>
    <span class="token keyword">static</span> <span class="token keyword">const</span> <span class="token keyword">unsigned</span> io_type <span class="token operator">=</span> nnet<span class="token operator">::</span>io_parallel<span class="token punctuation">;</span>
    <span class="token keyword">static</span> <span class="token keyword">const</span> <span class="token keyword">unsigned</span> reuse_factor <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>
    <span class="token keyword">static</span> <span class="token keyword">const</span> <span class="token keyword">unsigned</span> n_zeros <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
    <span class="token keyword">static</span> <span class="token keyword">const</span> <span class="token keyword">unsigned</span> n_nonzeros <span class="token operator">=</span> <span class="token number">320</span><span class="token punctuation">;</span>
    <span class="token keyword">static</span> <span class="token keyword">const</span> <span class="token keyword">bool</span> store_weights_in_bram <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">;</span>
    <span class="token keyword">typedef</span> ap_fixed<span class="token operator">&lt;</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token operator">&gt;</span> accum_t<span class="token punctuation">;</span>
    <span class="token keyword">typedef</span> model_default_t bias_t<span class="token punctuation">;</span>
    <span class="token keyword">typedef</span> model_default_t weight_t<span class="token punctuation">;</span>
    <span class="token keyword">typedef</span> ap_uint<span class="token operator">&lt;</span><span class="token number">1</span><span class="token operator">&gt;</span> index_t<span class="token punctuation">;</span>
<span class="token punctuation">}</span><span class="token punctuation">;</span>
</code></pre>
<p>It is at this stage that a user can even further configure their network HLS implementation in finer detail.</p>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="QUICKSTART.html" class="navigation navigation-prev " aria-label="Previous page: Quick Start">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="../COMMAND.html" class="navigation navigation-next " aria-label="Next page: Command help">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Configuration","level":"1.4.3","depth":2,"next":{"title":"Command help","level":"1.5","depth":1,"path":"COMMAND.md","ref":"COMMAND.md","articles":[]},"previous":{"title":"Quick Start","level":"1.4.2","depth":2,"path":"setup/QUICKSTART.md","ref":"setup/QUICKSTART.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":["prism","-highlight"],"pluginsConfig":{"fontSettings":{"theme":"sepia","family":"sans"},"prism":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"setup/CONFIGURATION.md","mtime":"2020-07-11T14:13:38.896Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2020-07-11T14:14:27.014Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

